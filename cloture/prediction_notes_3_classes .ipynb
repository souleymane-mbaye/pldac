{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "# Les instructions suivantes sont TRES utile pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments, notes = utils.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 et voila un triplette de bubblees rouges et pop je t inverse deux bubblees chez toi avec un noir biensur    pas assez tordu pour vous    alors que pensez vous des bubblees violets qui renvoient un des votres chez la planète adverse  ah ah   là je vous tiens  c est plus tactique qu il n y parait et bien retord   avec un peu de chance c est vrai  mais n est il pas encore plus agréable et jouissif de gagner même lorsque le sort s acharne contre vous  je n ai pas encore l extension mais elle sera bientôt mienne \n"
     ]
    }
   ],
   "source": [
    "print(notes[0],comments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = utils.binarisation(notes, nb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(cls)\n",
    "plt.title('Répartition des classes avant réequilibrage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Juste pour la visualisation à ne pas utiliser dans la suite \n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "com = count_vect.fit_transform(comments)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "comments_resample, cls_resample = rus.fit_resample(com, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cls_resample)\n",
    "plt.title('Répartition des classes apres réequilibrage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les mots les plus fréquenrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tri les mots par ordre décroissant de leurs fréquences, à lancer une seule fois c'est bon\n",
    "mots_freq = utils.words_frequencies(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 50 mots les plus fréquents: ['de', 'et', 'le', 'est', 'un', 'les', 'jeu', 'la', 'des', 'en', 'pas', 'pour', 'on', 'que', 'une', 'qui', 'il', 'mais', 'ce', 'du', 'plus', 'je', 'dans', 'ne', 'avec', 'très', 'bien', 'au', 'qu', 'tout', 'se', 'sur', 'sont', 'ou', 'vous', 'cartes', 'peu', 'par', 'même', 'si', 'joueurs', 'bon', 'partie', 'fait', 'peut', 'ai', 'faire', 'jouer', 'parties', 'ça']\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "print(f'Les {k} mots les plus fréquents: {mots_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variantes et évaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5560698565952009  f1-score: 0.5822237911132101\n",
      "Top 10 mots positifs:  ['déception', 'décevant', 'ratage', 'ennuyeux', 'désavantage', 'ennui', 'ascendant', 'affreux', 'perception', 'médiocre']\n",
      "Top 10 mots négatifs:  ['revivre', 'vindjeu', 'bémol', 'claustrophobia', 'pépite', 'réactions', 'restantes', 'régal', 'maximale', 'rythmées']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5877608973448815  f1-score: 0.6122275461602433\n",
      "Top 10 mots positifs:  ['déception', 'intérêt', 'ennui', 'ennuyeux', 'décevant', 'aucun', 'ennuie', 'pas', 'oie', 'aucune']\n",
      "Top 10 mots négatifs:  ['excellent', 'bémol', 'bon', 'agréable', 'bien', 'efficace', 'must', 'indispensable', 'parfait', 'attention']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.5531165696436178  f1-score: 0.5783588781035033\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stopwords.words('french'), nbins=False)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5823654692602585  f1-score: 0.6070099848781721\n",
      "Top 10 mots positifs:  ['déception', 'intérêt', 'ennui', 'ennuyeux', 'ennuie', 'décevant', 'ennuyé', 'aucun', 'déçu', 'chose']\n",
      "Top 10 mots négatifs:  ['excellent', 'bémol', 'bon', 'agréable', 'efficace', 'must', 'bien', 'parfait', 'permet', 'bonheur']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stopwords.words('french'), nbins=False)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopswords et les 200 termes les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5294334800511146  f1-score: 0.5562899752843692\n",
      "Top 10 mots positifs:  ['déception', 'décevant', 'ratage', 'ennuyé', 'error', 'ennuyeux', 'ennui', 'désavantage', 'ratée', 'convenu']\n",
      "Top 10 mots négatifs:  ['bémol', 'pépite', 'revivre', 'régal', 'bouder', 'assurée', 'maximale', 'disposer', 'vindjeu', 'bémols']\n"
     ]
    }
   ],
   "source": [
    "k = 200\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "stop_words = mots_k + stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5610393298310379  f1-score: 0.5865637089736605\n",
      "Top 10 mots positifs:  ['déception', 'intérêt', 'ennui', 'ennuyeux', 'décevant', 'ennuie', 'ennuyé', 'pire', 'aucun', 'aucune']\n",
      "Top 10 mots négatifs:  ['bémol', 'efficace', 'must', 'fluide', 'tendu', 'parfait', 'bonheur', 'attention', 'indispensable', 'plaisant']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes,nbins=False,stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopswords et les 2 000 termes les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.4456339627999432  f1-score: 0.47334867066460723\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "k = 2_000\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "stop_words = mots_k + stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5363623455913673  f1-score: 0.5619268894492955\n",
      "Top 10 mots positifs:  ['décept', 'décev', 'pir', 'désol', 'répétit', 'médiocr', 'mauv', 'chi', 'impossibl', 'poussi']\n",
      "Top 10 mots négatifs:  ['agréabl', 'efficac', 'reproch', 'fluid', 'vindjeu', 'parf', 'jouiss', 'hésit', 'rigolad', 'garant']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False, stop_words=stop_words, preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopswords et les 20 000 termes les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Random forest accuracy: 0.6148232287377537  f1-score: 0.4713929550977774\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "k = 20_000\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "stop_words = mots_k + stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Random forest accuracy: 0.6150788016470254  f1-score: 0.4715302100463098\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.4903592219224762  f1-score: 0.5188069858199154\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, stop_words=stop_words,preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.6079227601874201  f1-score: 0.6314528543138581\n",
      "Top 10 mots positifs:  ['intérêt', 'déception', 'pas', 'rien', 'trop', 'aucun', 'ennui', 'ennuyeux', 'aucune', 'répétitif']\n",
      "Top 10 mots négatifs:  ['excellent', 'bon jeu', 'un peu', 'bien', 'agréable', 'pas mal', 'très bon', 'pas trop', 'bon', 'bémol']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes , nbins=False,  ngram_range=(1, 2))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.6088314638648303  f1-score: 0.6275734445235349\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, ngram_range=(1, 2), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.6108192531591651  f1-score: 0.629609487507173\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False, ngram_range=(1, 2), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Random forest accuracy: 0.6150788016470254  f1-score: 0.4715302100463098\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.6216385063183303  f1-score: 0.6384526461737937\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, ngram_range=(1, 3))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.6216385063183303  f1-score: 0.6384526461737937\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, ngram_range=(1, 3))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.6129206304131762  f1-score: 0.6308749093881143\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, ngram_range=(1, 3), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Naïve Bayes\n",
      "Naïve bayes accuracy: 0.6108192531591651  f1-score: 0.629609487507173\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False, ngram_range=(1, 2), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5505608405509016  f1-score: 0.5766858433136628\n",
      "Top 10 mots positifs:  ['rendon', 'ratag', 'décept', 'atz', 'decept', 'alimentair', 'modelag', 'médiocr', 'différentiel', 'devenus']\n",
      "Top 10 mots négatifs:  ['revivr', 'dujardin', 'craign', 'hesit', 'vindjeu', 'surnombr', 'bémol', 'secou', 'ariv', 'maximal']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, stop_words=stop_words,preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.5777651568933693  f1-score: 0.6024762029108918\n",
      "Top 10 mots positifs:  ['décept', 'ennui', 'intérêt', 'aucun', 'décev', 'déçu', 'répétit', 'pir', 'oie', 'convaincu']\n",
      "Top 10 mots négatifs:  ['excellent', 'bémol', 'agréabl', 'bon', 'reproch', 'must', 'tendu', 'parf', 'efficac', 'fluid']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False, stop_words=stop_words,preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/souleymbaye/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/Users/souleymbaye/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x7/bmqxr1zd3lxd_kcxxw9physr0000gn/T/ipykernel_2435/2464694096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'french'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36mcount_vectorizer\u001b[0;34m(comments, classes, nbins, **count_vectorizer_args)\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcount_vectorizer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mclassifieur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36mclassifieur\u001b[0;34m(vectorizer, comments, classes)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassifieur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mrus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mlemmatized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mlemmatized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlemmatized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mlemmatized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mlemmatized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlemmatized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/souleymbaye/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, nbins=False, stop_words=stop_words,preprocessor=utils.lemmatize)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, nbins=False, stop_words=stop_words,preprocessor=utils.lemmatize)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

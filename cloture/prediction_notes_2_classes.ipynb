{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "# Les instructions suivantes sont TRES utile pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments, notes = utils.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 et voila un triplette de bubblees rouges et pop je t inverse deux bubblees chez toi avec un noir biensur    pas assez tordu pour vous    alors que pensez vous des bubblees violets qui renvoient un des votres chez la planète adverse  ah ah   là je vous tiens  c est plus tactique qu il n y parait et bien retord   avec un peu de chance c est vrai  mais n est il pas encore plus agréable et jouissif de gagner même lorsque le sort s acharne contre vous  je n ai pas encore l extension mais elle sera bientôt mienne \n"
     ]
    }
   ],
   "source": [
    "print(notes[0],comments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = utils.binarisation(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(cls)\n",
    "plt.title('Répartition des classes avant réequilibrage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Juste pour la visualisation à ne pas utiliser dans la suite \n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "com = count_vect.fit_transform(comments)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "comments_resample, cls_resample = rus.fit_resample(com, cls)\n",
    "\n",
    "plt.hist(cls_resample)\n",
    "plt.title('Répartition des classes après réequilibrage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les mots les plus fréquenrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tri les mots par ordre décroissant de leurs fréquences, à lancer une seule fois c'est bon\n",
    "mots_freq = utils.words_frequencies(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 50 mots les plus fréquents: ['de', 'et', 'le', 'est', 'un', 'les', 'jeu', 'la', 'des', 'en', 'pas', 'pour', 'on', 'que', 'une', 'qui', 'il', 'mais', 'ce', 'du', 'plus', 'je', 'dans', 'ne', 'avec', 'très', 'bien', 'au', 'qu', 'tout', 'se', 'sur', 'sont', 'ou', 'vous', 'cartes', 'peu', 'par', 'même', 'si', 'joueurs', 'bon', 'partie', 'fait', 'peut', 'ai', 'faire', 'jouer', 'parties', 'ça']\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "print(f'Les {k} mots les plus fréquents: {mots_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variantes et évaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8091722277438591  f1-score: 0.8251763313043985\n",
      "Top 10 mots positifs:  ['excellent', 'bémol', 'roule', 'foncez', 'pépite', 'régal', 'volontiers', 'abuser', 'redoutable', 'mac']\n",
      "Top 10 mots négatifs:  ['décevant', 'fade', 'ennuyeux', 'ennuyé', 'poussif', 'ennui', 'ascendant', 'revendu', 'interet', 'gâché']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8240238534715321  f1-score: 0.8373630018941829\n",
      "Top 10 mots positifs:  ['excellent', 'bon', 'bémol', 'bien', 'adore', 'agréable', 'parfait', 'efficace', 'attention', 'aussi']\n",
      "Top 10 mots négatifs:  ['intérêt', 'déception', 'aucune', 'pas', 'ennui', 'ennuyeux', 'bof', 'rien', 'déçu', 'répétitif']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVM\n",
      "Svm accuracy: 0.7779071418429646  f1-score: 0.7994110672230202\n",
      "Top 10 mots positifs:  ['nijas', 'datait', 'mikerinos', 'garanties', 'remplacerais', 'octroie', 'fusent', 'malandrin', 'pépite', 'galactica']\n",
      "Top 10 mots négatifs:  ['réfléchisseurs', 'marquante', 'ascendant', 'tiendrai', 'passionner', 'euphémisme', 'séduisants', 'transcendé', 'permettraient', 'alcoolisée']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8197359079937526  f1-score: 0.8337093718502294\n",
      "Top 10 mots positifs:  ['excellent', 'bon', 'bémol', 'bien', 'agréable', 'adore', 'efficace', 'bonheur', 'parfait', 'réussite']\n",
      "Top 10 mots négatifs:  ['déception', 'intérêt', 'déçu', 'ennuyeux', 'ennui', 'aucune', 'ennuie', 'bof', 'décevant', 'répétitif']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopswords et les 200 termes les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.7889819679114014  f1-score: 0.8085742341093869\n",
      "Top 10 mots positifs:  ['bémol', 'pépite', 'régal', 'priver', 'assurée', 'foncez', 'mac', 'redoutable', 'thématiquement', 'jouissif']\n",
      "Top 10 mots négatifs:  ['décevant', 'ennuyé', 'ennuyeux', 'poussif', 'fade', 'ennui', 'déception', 'revendu', 'accroché', 'interet']\n"
     ]
    }
   ],
   "source": [
    "k = 200\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "stop_words = mots_k + stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8069572625301717  f1-score: 0.8228293706105443\n",
      "Top 10 mots positifs:  ['bémol', 'efficace', 'fluide', 'adore', 'réussite', 'bonheur', 'bravo', 'attention', 'parfait', 'excellente']\n",
      "Top 10 mots négatifs:  ['déception', 'intérêt', 'ennuyeux', 'ennui', 'aucune', 'déçu', 'bof', 'ennuie', 'décevant', 'accroché']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopswords et les 2 000 termes les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Random forest accuracy: 0.8233423257134743  f1-score: 0.7972948891404649\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "k = 2_000\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "stop_words = mots_k + stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.7831889819679114  f1-score: 0.8034957584216009\n",
      "Top 10 mots positifs:  ['agréabl', 'efficac', 'fluid', 'reproch', 'parf', 'ador', 'auss', 'fonc', 'vindjeu', 'hésit']\n",
      "Top 10 mots négatifs:  ['décept', 'décev', 'répétit', 'pir', 'désol', 'accroch', 'fad', 'mauv', 'dommag', 'malheur']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stop_words, preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopswords et les 20 000 termes les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Random forest accuracy: 0.8434189975862558  f1-score: 0.7761782269085544\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "k = 20_000\n",
    "mots_k =[m for m,f in mots_freq[:k]]\n",
    "stop_words = mots_k + stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Random forest accuracy: 0.84390174641488  f1-score: 0.7764252283291145\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.6140281130200199  f1-score: 0.6674449468019736\n",
      "Top 10 mots positifs:  ['revivr', 'hav', 'réactualis', 'prestat', 'rid', 'robb', 'jouiss', 'fonc', 'proxim', 'espagn']\n",
      "Top 10 mots négatifs:  ['atz', 'décept', 'cred', 'fad', 'décev', 'obsolet', 'fatid', 'désol', 'farfadet', 'afflig']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stop_words,preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVM\n",
      "Svm accuracy: 0.842652278858441  f1-score: 0.8529017047719054\n",
      "Top 10 mots positifs:  ['excellent', 'bon jeu', 'très bon', 'pas trop', 'pas mal', 'un peu', 'adore', 'bémol', 'bien', 'bon petit']\n",
      "Top 10 mots négatifs:  ['déception', 'intérêt', 'pas', 'trop', 'ennuyeux', 'ennui', 'aucune', 'déçu', 'bof', 'décevant']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes,  ngram_range=(1, 2))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8252449240380519  f1-score: 0.8387773692039843\n",
      "Top 10 mots positifs:  ['excellent', 'bon petit', 'bémol', 'must', 'bravo', 'très bon', 'bonheur', 'bonne extension', 'peu long', 'excellente']\n",
      "Top 10 mots négatifs:  ['ennuyeux', 'ennui', 'décevant', 'bof', 'déception', 'accroché', 'ennuie', 'ennuyé', 'nul', 'fade']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, ngram_range=(1, 2), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVM\n",
      "Svm accuracy: 0.833962799943206  f1-score: 0.8456417971666085\n",
      "Top 10 mots positifs:  ['excellent', 'bon jeu', 'très bon', 'bémol', 'bon petit', 'adore', 'bonheur', 'agréable', 'parfait', 'réussite']\n",
      "Top 10 mots négatifs:  ['déception', 'intérêt', 'ennui', 'ennuie', 'déçu', 'ennuyeux', 'répétitif', 'aucune', 'décevant', 'bof']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, ngram_range=(1, 2), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Random forest accuracy: 0.84390174641488  f1-score: 0.7764252283291145\n",
      "Poids des mots positifs et négatifs non connus, entre guillemets !\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stop_words)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8352406644895641  f1-score: 0.846961122751799\n",
      "Top 10 mots positifs:  ['excellent', 'pas mal', 'adore', 'pas trop', 'excellente', 'indispensable', 'parfait', 'très bon', 'bémol', 'génial']\n",
      "Top 10 mots négatifs:  ['bof', 'ennuyeux', 'ennui', 'déception', 'intérêt', 'nul', 'décevant', 'déçu', 'aucune', 'pff']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, ngram_range=(1, 3))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8352406644895641  f1-score: 0.846961122751799\n",
      "Top 10 mots positifs:  ['excellent', 'pas mal', 'adore', 'pas trop', 'excellente', 'indispensable', 'parfait', 'très bon', 'bémol', 'génial']\n",
      "Top 10 mots négatifs:  ['bof', 'ennuyeux', 'ennui', 'déception', 'intérêt', 'nul', 'décevant', 'déçu', 'aucune', 'pff']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, ngram_range=(1, 3))\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8251313360783757  f1-score: 0.8386725771137692\n",
      "Top 10 mots positifs:  ['excellent', 'bémol', 'must', 'adore', 'bonheur', 'très bon', 'bravo', 'excellente', 'parfait', 'peu long']\n",
      "Top 10 mots négatifs:  ['ennuyeux', 'bof', 'ennui', 'déception', 'accroché', 'décevant', 'ennuie', 'intérêt', 'nul', 'convaincu']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.count_vectorizer(comments, notes, ngram_range=(1, 3), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVM\n",
      "Svm accuracy: 0.833962799943206  f1-score: 0.8456417971666085\n",
      "Top 10 mots positifs:  ['excellent', 'bon jeu', 'très bon', 'bémol', 'bon petit', 'adore', 'bonheur', 'agréable', 'parfait', 'réussite']\n",
      "Top 10 mots négatifs:  ['déception', 'intérêt', 'ennui', 'ennuie', 'déçu', 'ennuyeux', 'répétitif', 'aucune', 'décevant', 'bof']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, ngram_range=(1, 2), max_df=0.5, stop_words=stopwords.words('french'))\n",
    "utils.top_words(model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVM\n",
      "Svm accuracy: 0.775976146528468  f1-score: 0.7976601213545522\n",
      "Top 10 mots positifs:  ['nij', 'azul', 'keyring', 'tempil', 'ela', 'joyeu', 'déchet', 'temprois', 'bong', 'carbon']\n",
      "Top 10 mots négatifs:  ['rendon', 'ascend', 'fluiditel', 'réfléchisseur', 'atz', 'galvaud', 'boitesvoil', 'descel', 'récif', 'navr']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stop_words,preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Logistic regression accuracy: 0.8133465852619622  f1-score: 0.8284838145108614\n",
      "Top 10 mots positifs:  ['excellent', 'bémol', 'bon', 'agréabl', 'efficac', 'bien', 'parf', 'reproch', 'must', 'ador']\n",
      "Top 10 mots négatifs:  ['ennui', 'décept', 'intérêt', 'aucun', 'déçu', 'bof', 'décev', 'répétit', 'accroch', 'dommag']\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stop_words,preprocessor=utils.stem)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/souleymbaye/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/Users/souleymbaye/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x7/bmqxr1zd3lxd_kcxxw9physr0000gn/T/ipykernel_2551/3922044236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'french'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36mcount_vectorizer\u001b[0;34m(comments, classes, nbins, **count_vectorizer_args)\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcount_vectorizer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mclassifieur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36mclassifieur\u001b[0;34m(vectorizer, comments, classes)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassifieur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mrus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mlemmatized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mlemmatized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlemmatized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MesDocs/UPMC/UPMC_DAC_22/S2/PLDAC/cloture/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mlemmatized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mlemmatized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlemmatized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/souleymbaye/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "model, vectorizer = utils.count_vectorizer(comments, notes, stop_words=stop_words,preprocessor=utils.lemmatize)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vectorizer = utils.tfidf_vectorizer(comments, notes, stop_words=stop_words,preprocessor=utils.lemmatize)\n",
    "utils.top_words(model, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

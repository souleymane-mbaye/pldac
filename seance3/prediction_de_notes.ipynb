{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction des notes par les commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo  import MongoClient\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection à la base de données MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = MongoClient(host=\"localhost\", port=27017)\n",
    "db_mongo = client.PLDAC_01\n",
    "avis = db_mongo.avis\n",
    "\n",
    "# avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notes: 0 commentaire: 0\n"
     ]
    }
   ],
   "source": [
    "commentaires,notes = [],[]\n",
    "\n",
    "for rep in avis.find({}):\n",
    "  commentaire = rep['comment'] if 'comment' in rep else \"\"\n",
    "  # lignes de commentaire vide sont ignorées\n",
    "  if commentaire == \"\":\n",
    "    continue\n",
    "  \n",
    "  note = rep['note']\n",
    "  \n",
    "  notes.append(note)\n",
    "  commentaires.append(commentaire)\n",
    "notes,commentaires = np.array(notes),np.array(commentaires)\n",
    "print('notes:',len(notes),'commentaire:',len(commentaires))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation de densité de la distribution des notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "sns.displot(notes[:2000],kde=True)\n",
    "plt.title('Distribution des notes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.displot(notes,kde=True)\n",
    "plt.title('Distribution des notes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by KernelDensity.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m X_plot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1000\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# estimation de densité par noyaux gaussiens\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m kde \u001b[38;5;241m=\u001b[39m \u001b[43mKernelDensity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgaussian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# calcul de la densité pour les données de X_plot\u001b[39;00m\n\u001b[0;32m      9\u001b[0m density \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(kde\u001b[38;5;241m.\u001b[39mscore_samples(X_plot)) \u001b[38;5;241m*\u001b[39m notes\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_kde.py:225\u001b[0m, in \u001b[0;36mKernelDensity.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbandwidth_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbandwidth\n\u001b[1;32m--> 225\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    229\u001b[0m         sample_weight, X, DTYPE, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by KernelDensity."
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "X = notes.reshape((notes.size,1))\n",
    "# préparer les points où on calculera la densité\n",
    "X_plot = np.linspace(0, 10, 1000)[:, np.newaxis]\n",
    "\n",
    "# estimation de densité par noyaux gaussiens\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.75).fit(X)\n",
    "# calcul de la densité pour les données de X_plot\n",
    "density = np.exp(kde.score_samples(X_plot)) * notes.size\n",
    "\n",
    "# affichage : vraie densité et estimation\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(X[:,0], bins=10, fc='blue', alpha=0.2, label='Vraie densité')\n",
    "ax.plot(X_plot[:,0], density, '-', label=\"Estimation\",color='red')\n",
    "ax.plot(X[:, 0], -0.005 - 0.01 * np.random.random(X.shape[0]), '+k')\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui sup\n",
    "def supprimer_les_nombres(docs):\n",
    "    \"\"\" Fonction qui supprime tous les nombres dans la chaine de caractères doc\n",
    "\n",
    "    Args:\n",
    "        doc (string): chaine de caractère à emputer les nombres\n",
    "\n",
    "    Returns:\n",
    "        string: chaine de caractère sans les nombres\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array([re.sub('[0-9]+', '', doc) for doc in docs])\n",
    "\n",
    "def supprimer_la_ponctuation(docs):\n",
    "    \"\"\" Fonction qui supprime tous les nombres dans la chaine de caractères doc\n",
    "\n",
    "    Args:\n",
    "        doc (string): chaine de caractère à emputer les nombres\n",
    "\n",
    "    Returns:\n",
    "        string: chaine de caractère sans les nombres\n",
    "    \"\"\"\n",
    "    \n",
    "    punc = string.punctuation \n",
    "    punc += '\\n\\r\\t'\n",
    "    return np.array([doc.translate(str.maketrans(punc, ' ' * len(punc))) for doc in docs])\n",
    "\n",
    "def pretraitement(docs):\n",
    "    docs = np.array([doc.lower() for doc in docs])\n",
    "    docs = supprimer_les_nombres(docs)\n",
    "    docs = supprimer_la_ponctuation(docs)\n",
    "\n",
    "    return docs\n",
    "commentaires = pretraitement(commentaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = np.array(['SofiA56','23NolwenN','34','SouleymanE62'])\n",
    "pretraitement(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(commentaires[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comptages des occurrences des mots et loi Zipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loi Zipf \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(commentaires)  # creer le bow\n",
    "sum_words = bag_of_words.sum(axis=0) # nb occurrences de chaque mot\n",
    "words_freq = [(str(word), sum_words[0, idx]) for word, idx in     vectorizer.vocabulary_.items()] # couple (mot, freq)\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)  # trie par freq decroissante\n",
    "print('nombre de mots:',len(words_freq))\n",
    "\n",
    "nmots = 50\n",
    "x = [w for w,f in words_freq[:nmots]]\n",
    "y = [f for w,f in words_freq[:nmots]]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x,y)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les k mots les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ord = [w for w,f in words_freq]\n",
    "k = 200\n",
    "print([w for w in words_ord[:k]])  # les k mots les plus fréquents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les k mots les moins fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les moins fréquents majoritairement des erreurs de frappes et des exagérations\n",
    "print([w for w in words_ord[-k:]])  # les k mots les moins fréquents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rééquilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_en = np.around(notes)\n",
    "notes_un,nb_notes = np.unique(notes_en,return_counts=True)\n",
    "print('\\n  Somme cumulée croissante:',np.cumsum(nb_notes)/nb_notes.sum())\n",
    "print('Distribution des notes:',nb_notes)\n",
    "\n",
    "N_min = np.min(nb_notes)\n",
    "print('Minimum des notes:',N_min)\n",
    "commentaires_eq,notes_eq = [],[]\n",
    "notes_float_eq = []\n",
    "for cl in notes_un:\n",
    "  i_cl = notes_en == cl\n",
    "  commentaires_cl = commentaires[i_cl]\n",
    "  notes_cl = notes_en[i_cl]\n",
    "  notes_float_cl = notes[i_cl]\n",
    "  \n",
    "  # Un petit shuffle\n",
    "  i_rand = np.arange(commentaires_cl.shape[0])\n",
    "  np.random.shuffle(i_rand)\n",
    "  commentaires_cl = commentaires_cl[i_rand[:N_min]]\n",
    "\n",
    "  # chaque classe présente N_min lignes\n",
    "  for i in range(N_min): \n",
    "    commentaires_eq.append(commentaires_cl[i])\n",
    "    notes_eq.append(notes_cl[i])\n",
    "    notes_float_eq.append(notes_float_cl[i])\n",
    "\n",
    "commentaires_eq,notes_eq = np.array(commentaires_eq),np.array(notes_eq)\n",
    "notes_float_eq = np.array(notes_float_eq)\n",
    "print('Nouvelle taille',len(commentaires_eq),len(notes_eq),N_min*notes_un.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(commentaires_eq),len(notes_eq),N_min*notes_un.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kde sur les classes rééquilibrées(juste pour voir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec des notes float\n",
    "plt.figure()\n",
    "sns.displot(notes_float_eq,kde=True)\n",
    "plt.title('Distribution des notes rééquilibrées')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec les notes en entier\n",
    "plt.figure()\n",
    "sns.displot(notes_eq,kde=True)\n",
    "plt.title('Distribution des notes rééquilibrées')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mots les plus fréquents après rééquilibre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loi Zipf \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words_eq = vectorizer.fit_transform(commentaires_eq)  # creer le bow\n",
    "sum_words_eq = bag_of_words_eq.sum(axis=0) # nb occurrences de chaque mot\n",
    "words_freq_eq = [(str(word), sum_words_eq[0, idx]) for word, idx in     vectorizer.vocabulary_.items()] # couple (mot, freq)\n",
    "words_freq_eq =sorted(words_freq_eq, key = lambda x: x[1], reverse=True)  # trie par freq decroissante\n",
    "print('nombre de mots:',len(words_freq_eq))\n",
    "\n",
    "nmots = 50\n",
    "x = [w for w,f in words_freq_eq[:nmots]]\n",
    "y = [f for w,f in words_freq_eq[:nmots]]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x,y)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ord_eq = [w for w,f in words_freq_eq]\n",
    "k = 200\n",
    "print([w for w in words_ord_eq[:k] if w not in stopwords.words('french')])  # les k mots les plus fréquents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud de tous les commentaires(classes confondues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS # Note: this is the default option    \n",
    "\n",
    "corpus = list(commentaires_eq)\n",
    "corpus = \" \".join(corpus)\n",
    "# print(corpus[:50])\n",
    "wordcloud = WordCloud(background_color='white', stopwords = STOPWORDS, max_words=100).generate(corpus) \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud pour chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0 # les k motes les plus fréquents à ne pas considérer\n",
    "for i in range(notes_un.shape[0]):\n",
    "  \n",
    "  # commentaires de chaque note\n",
    "  i_commentaire_note = notes_eq == notes_un[i]\n",
    "  commentaire_note = commentaires_eq[i_commentaire_note]\n",
    "  \n",
    "  # les mots les plus fréquent de chaque note\n",
    "  corpus_note = \" \".join(list(commentaire_note))\n",
    "  wordcloud = WordCloud(background_color='white', stopwords = [w for w in words_ord[:k]], max_words=100).generate(corpus_note)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.imshow(wordcloud)\n",
    "  plt.title('note '+str(i))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud de chaque classe sans les k mots les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "k = 200 # les k motes les plus fréquents à ne pas considérer\n",
    "stopwords_list = stopwords.words('french') + [w for w in words_ord[:k]]\n",
    "\n",
    "for i in range(notes_un.shape[0]):\n",
    "  \n",
    "  # commentaires de chaque note\n",
    "  i_commentaire_note = notes_eq == notes_un[i]\n",
    "  commentaire_note = commentaires_eq[i_commentaire_note]\n",
    "  \n",
    "  # les mots les plus fréquent de chaque note\n",
    "  corpus_note = \" \".join(list(commentaire_note))\n",
    "  wordcloud = WordCloud(background_color='white', stopwords = stopwords_list, max_words=100).generate(corpus_note)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.imshow(wordcloud)\n",
    "  plt.title('note '+str(i))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud en biclasse sans les k mots les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200 # les k motes les plus fréquents à ne pas considérer\n",
    "stopwords_list = stopwords.words('french') + [w for w in words_ord[:k]]\n",
    "\n",
    "# commentaires des notes négatives\n",
    "i_commentaire_note = notes_eq <= 5\n",
    "commentaire_note = commentaires_eq[i_commentaire_note]\n",
    "\n",
    "# les mots les plus fréquent de chaque note\n",
    "corpus_note = \" \".join(list(commentaire_note))\n",
    "wordcloud = WordCloud(background_color='white', stopwords = stopwords_list, max_words=100).generate(corpus_note)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.title('notes de 0 à 5')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# commentaires des notes positives\n",
    "i_commentaire_note = notes_eq > 5\n",
    "commentaire_note = commentaires_eq[i_commentaire_note]\n",
    "\n",
    "# les mots les plus fréquent de chaque note\n",
    "corpus_note = \" \".join(list(commentaire_note))\n",
    "wordcloud = WordCloud(background_color='white', stopwords = stopwords_list, max_words=100).generate(corpus_note)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.title('notes de 6 à 10')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit des mots négatifs sur les petites notes (jamais,dommage,manque,ni,envie,pourtant,déçu,passe) et positifs(belle,possible,nouvelle,interaction,ressource,facile,objectif) dans les notes hautes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction des notes à partir des commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = commentaires_eq,notes_eq\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0) \n",
    "\n",
    "tt = len(y_train)+len(y_test)\n",
    "print(len(y_train)/tt,len(y_test)/tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les caractéristiques les plus importantes pour un modèle\n",
    "def mots_importants(model,n=10):\n",
    "  feature_weights = model.coef_[0]\n",
    "  top_features = {\n",
    "      'positive': [vectorizer.get_feature_names_out()[i] for i in feature_weights.argsort()[-n:][::-1]],\n",
    "      'negative': [vectorizer.get_feature_names_out()[i] for i in feature_weights.argsort()[:n]]\n",
    "  }\n",
    "\n",
    "  \n",
    "  return top_features['positive'],top_features['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "def prediction(vect=CountVectorizer,**args):\n",
    "  \n",
    "  vectorizer = vect(**args)\n",
    "\n",
    "  X = vectorizer.fit_transform(corpus)\n",
    "  # print(vectorizer.get_feature_names()[:10]) # we only print a few\n",
    "  print(X.shape)\n",
    "\n",
    "  #Naïve Bayes\n",
    "  nb_clf = MultinomialNB()\n",
    "  nb_clf.fit(X, classes)\n",
    "\n",
    "\n",
    "  #Logistic Regression\n",
    "  lr_clf = LogisticRegression(random_state=0, solver='lbfgs',max_iter=1000,n_jobs=-1)\n",
    "  lr_clf.fit(X, classes)\n",
    "\n",
    "  #Linear SVM\n",
    "  svm_clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "  svm_clf.fit(X, classes)\n",
    "\n",
    "\n",
    "  X_t = vectorizer.transform(corpus_test)\n",
    "\n",
    "  pred_nb = nb_clf.predict(X_t)\n",
    "  pred_lr = lr_clf.predict(X_t)\n",
    "  pred_svm = svm_clf.predict(X_t)\n",
    "\n",
    "\n",
    "  print(f\"Naïve Bayes accuracy: {accuracy_score(classes_test, pred_nb)}\")\n",
    "  print(f\"Logistic Regression accuracy: {accuracy_score(classes_test, pred_lr)}\")\n",
    "  print(f\"SVM accuracy: {accuracy_score(classes_test, pred_svm)}\")\n",
    "\n",
    "  return nb_clf,lr_clf,svm_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec tous les mots du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "r = prediction(CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons des performances meilleurs que celles de la fois fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans les k=200 mots les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "k = 200\n",
    "r = prediction(CountVectorizer,stop_words=[w for w in words_ord[:k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans les k=200 mots les plus fréquents et les 200 moins fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 200\n",
    "r = prediction(CountVectorizer,stop_words=[w for w in words_ord[:k]] + [w for w in words_ord[-k:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans les k=1_000 mots les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 1_000\n",
    "stopwords_list = stopwords.words('french') + [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "r = prediction(CountVectorizer,stop_words=stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans les mots les plus fréquents du français"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 2_000\n",
    "stopwords_list = stopwords.words('french') #+ [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "r = prediction(CountVectorizer,stop_words=stopwords_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans les k=2_000 mots les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 2_000\n",
    "stopwords_list = [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "r = prediction(CountVectorizer,stop_words=stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avec des bigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 200\n",
    "# stopwords_list = stopwords.words('french') #+ [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "stopwords_list = [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "r = prediction(CountVectorizer,stop_words=stopwords_list,ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec des trigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 200\n",
    "# stopwords_list = stopwords.words('french') #+ [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "stopwords_list = [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "r = prediction(CountVectorizer,stop_words=stopwords_list,ngram_range=(1,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigrammes et trigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "classes_test = y_test\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 200\n",
    "# stopwords_list = stopwords.words('french') #+ [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "stopwords_list = [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "r = prediction(CountVectorizer,stop_words=stopwords_list,ngram_range=(2,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction avec séparation des notes en deux classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "# classification binaire decoupage (0 à 5 -> -1) (6 à 10 -> 1)\n",
    "classes = [1 if note>5 else -1 for note in y_train]\n",
    "corpus = X_train\n",
    "classes_test = [1 if note>5 else -1 for note in y_test]\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 200\n",
    "stopwords_list = stopwords.words('french') #+ [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les mots les plus importants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_pos,mots_neg = mots_importants(lr_clf)\n",
    "print('Mots positifs :',mots_pos)\n",
    "print('Mots negatifs :',mots_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_pos,mots_neg = mots_importants(svm_clf)\n",
    "print('Mots positifs :',mots_pos)\n",
    "print('Mots negatifs :',mots_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction avec séparation des notes en deux classes sans les k=200 moins fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "# classification binaire decoupage (0 à 5 -> -1) (6 à 10 -> 1)\n",
    "classes = [1 if note>5 else -1 for note in y_train]\n",
    "corpus = X_train\n",
    "classes_test = [1 if note>5 else -1 for note in y_test]\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 200\n",
    "stop_words = stopwords.words('french') + [w for w in words_ord[:k]] + [w for w in words_ord[-2*k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction avec séparation des notes en deux classes sans les k=2_000 moins fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "# classification binaire decoupage (0 à 5 -> -1) (6 à 10 -> 1)\n",
    "classes = [1 if note>5 else -1 for note in y_train]\n",
    "corpus = X_train\n",
    "classes_test = [1 if note>5 else -1 for note in y_test]\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 2000\n",
    "stop_words = stopwords.words('french') + [w for w in words_ord[:k]] + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En enlevant les 20_000 termes les fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "# classification binaire decoupage (0 à 5 -> -1) (6 à 10 -> 1)\n",
    "classes = [1 if note>5 else -1 for note in y_train]\n",
    "corpus = X_train\n",
    "classes_test = [1 if note>5 else -1 for note in y_test]\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 20_000\n",
    "stop_words = stopwords.words('french') + [w for w in words_ord[:k]] + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec du steming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "def stem(docs):\n",
    "  docs_stem = []\n",
    "  stemmer = FrenchStemmer()\n",
    "  \n",
    "  for i in range(docs.shape[0]):\n",
    "    tokens = str(docs[i]).split()\n",
    "\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    stemmed_text = \" \".join(stemmed_tokens)\n",
    "    docs_stem.append(stemmed_text)\n",
    "  \n",
    "  return np.array(docs_stem)\n",
    "\n",
    "commentaires_stem = stem(commentaires)\n",
    "corpus_stem = stem(X_train)\n",
    "corpus_test_stem = stem(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(commentaires[0],'\\n  -->\\n',commentaires_stem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0],'\\n  -->\\n',corpus_stem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comptages des occurrences des mots et loi Zipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loi Zipf \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words_stem = vectorizer.fit_transform(commentaires_stem)  # creer le bow\n",
    "sum_words_stem = bag_of_words_stem.sum(axis=0) # nb occurrences de chaque mot\n",
    "words_freq_stem = [(str(word), sum_words_stem[0, idx]) for word, idx in     vectorizer.vocabulary_.items()] # couple (mot, freq)\n",
    "words_freq_stem =sorted(words_freq_stem, key = lambda x: x[1], reverse=True)  # trie par freq decroissante\n",
    "print('nombre de mots:',len(words_freq_stem))\n",
    "\n",
    "nmots = 50\n",
    "x = [w for w,f in words_freq_stem[:nmots]]\n",
    "y = [f for w,f in words_freq_stem[:nmots]]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x,y)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ord_stem = [w for w,f in words_freq_stem]\n",
    "k = 200\n",
    "print([w for w in words_ord_stem[:k]])  # les k mots les plus fréquents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction en biclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "classes = [1 if note>5 else -1 for note in y_train]\n",
    "corpus = corpus_stem\n",
    "classes_test = [1 if note>5 else -1 for note in y_test]\n",
    "corpus_test = corpus_test_stem\n",
    "\n",
    "k = 200\n",
    "stopwords_list = stopwords.words('french') #+ [w for w in words_ord[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steming sans les k mots les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "stopwords_list =  [w for w in words_ord_stem[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steming plus bigramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "stopwords_list =  [w for w in words_ord_stem[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list,ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steming plus trigramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "stopwords_list =  [w for w in words_ord_stem[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list,ngram_range=(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "stopwords_list =  [w for w in words_ord_stem[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list,ngram_range=(2,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "stopwords_list =  [w for w in words_ord_stem[:k]] # + [w for w in words_ord[-k:]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(CountVectorizer,stop_words=stopwords_list,ngram_range=(2,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "use_idf=True\n",
    "smooth_idf=True\n",
    "sublinear_tf=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "# classification binaire decoupage (0 à 5 -> -1) (6 à 10 -> 1)\n",
    "classes = [1 if note>5 else -1 for note in y_train]\n",
    "corpus = X_train\n",
    "classes_test = [1 if note>5 else -1 for note in y_test]\n",
    "corpus_test = X_test\n",
    "\n",
    "k = 200\n",
    "stopwords_list =  [w for w in words_ord_stem[:k]]\n",
    "\n",
    "nb_clf,lr_clf,svm_clf = prediction(TfidfVectorizer,stop_words=stopwords_list,use_idf= use_idf, smooth_idf=smooth_idf, sublinear_tf=sublinear_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction des notes avec la régression linéaire (pas satisfaisant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage en supprimant les k mots les plus fréquents\n",
    "\n",
    "classes = y_train\n",
    "corpus = X_train\n",
    "\n",
    "k = 2000\n",
    "vectorizer = CountVectorizer(stop_words=[w for w in words_ord[:k]])\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "# print(vectorizer.get_feature_names()[:10]) # we only print a few\n",
    "X = X.toarray().astype(float)\n",
    "X_t = vectorizer.transform(X_test)\n",
    "X_t = X_t.toarray().astype(float)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation sur les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(X,max_cols=[],min_cols=[]):\n",
    "  if len(max_cols) == 0:\n",
    "    max_cols = X.max(axis=0)  # max de chaque colonne\n",
    "  if len(min_cols) == 0:\n",
    "    min_cols = X.min(axis=0)  # min de chaque colonne\n",
    "\n",
    "  for j in range(X.shape[1]):\n",
    "    max_c,min_c = max_cols[j], min_cols[j]\n",
    "    d = max_c - min_c\n",
    "    for i in range(X.shape[0]):\n",
    "      if d == 0:\n",
    "        X[i,j] = 0  # pour eviter NaN\n",
    "      else:\n",
    "        X[i,j] = (X[i,j] - min_c) / d\n",
    "\n",
    "  return X,max_cols,min_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_n,max_cols,min_cols = normalise(X)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_n, classes)\n",
    "\n",
    "X_t_n,max_cols,min_cols = normalise(X_t,max_cols,min_cols)\n",
    "\n",
    "pred_lr = lr.predict(X_t_n)\n",
    "\n",
    "err = np.abs(y_test-pred_lr)\n",
    "err = err.sum() / err.shape[0]\n",
    "\n",
    "print(f\"Linear Regression score: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering avec KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime les colonnes des mots frequents\n",
    "k = 200\n",
    "words_un = [w for w,f in words_freq[:k]]\n",
    "nom_cols = [word for word, idx in vectorizer.vocabulary_.items() if word not in words_un]\n",
    "i_cols = [idx for word, idx in vectorizer.vocabulary_.items() if word not in words_un]\n",
    "bow = bag_of_words[:,i_cols]\n",
    "\n",
    "print(len(nom_cols),len(i_cols),'\\n',bag_of_words.shape,bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 11\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0, max_iter=100).fit(bow)\n",
    "y_pred = kmeans.predict(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting clusters:\n",
    "l_cl_major = []\n",
    "for c in range(n_clusters):\n",
    "  i_cl = y_pred == c\n",
    "  cls,nb_cls = np.unique(notes[i_cl],return_counts=True)\n",
    "  i_cls_trie = np.argsort(nb_cls)\n",
    "  c_major = cls[i_cls_trie[0]]\n",
    "  l_cl_major.append(c_major)\n",
    "  sum_words = bow[i_cl].sum(axis=0).tolist()[0]\n",
    "  print('cluster:',c,'classe maj:',c_major,sum_words[:3])\n",
    "  \n",
    "  # recopie chaque mot le nombre de fois qu'il est présent dans le cluster\n",
    "  corpus_cl = []\n",
    "  for i in range(len(nom_cols)):\n",
    "    corpus_cl += [nom_cols[i]] * sum_words[i]\n",
    "  corpus_cl = \" \".join(corpus_cl)\n",
    "  wordcloud = WordCloud(background_color='white', stopwords = [], max_words=100).generate(corpus_cl)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.imshow(wordcloud)\n",
    "  plt.title(i_cls_trie[0])\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation en 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation en 2d mais il ne passe, trop de temps puis il crache\n",
    "k = 200\n",
    "vectorizer = CountVectorizer(lowercase=True,stop_words=[w for w in words_ord[:k]])\n",
    "\n",
    "corpus = list(commentaires_eq)\n",
    "corpus = \" \".join(corpus)\n",
    "# print(corpus[:5],commentaires_eq[0])\n",
    "Xu = vectorizer.fit_transform(commentaires_eq)\n",
    "print(Xu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xu = Xu.toarray()\n",
    "# U,S,V = np.linalg.svd(Xu.toarray(), full_matrices=False)\n",
    "lam, V = np.linalg.eig(Xu.T@Xu)\n",
    "\n",
    "# tri et sélection des 2 vecteurs associés aux 2 plus grandes valeurs propres \n",
    "lam_tries_arg = np.argsort(lam)\n",
    "lam_2_max = np.sort(lam_tries_arg[-2:])\n",
    "vp = (V[:,lam_2_max])\n",
    "Xu2D = Xu @ vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage (plot) avec un code couleur pour les classes\n",
    "plt.figure()\n",
    "for c in range(0,10+1):\n",
    "  Xc = Xu2D[notes==c]\n",
    "  plt.scatter(Xc[:,0],Xc[:,1])\n",
    "\n",
    "plt.legend(np.arange(10+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

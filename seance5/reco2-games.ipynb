{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de7f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo  import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import decomposition, naive_bayes, preprocessing, model_selection, metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import model_selection\n",
    "#! pip install scikit-surprise\n",
    "from surprise import NormalPredictor, BaselineOnly, SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34814b",
   "metadata": {},
   "source": [
    "# Chargement des données AVIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397272d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host=\"localhost\", port=27017)\n",
    "db = client[\"PLDAC_01\"]\n",
    "collection = db[\"avis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ea1183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monsieur Guillaume</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morlockbob</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SwatSh</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Timi JeuxATheme</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prunelles</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author      title  note\n",
       "0  Monsieur Guillaume  Mariposas   8.0\n",
       "1          morlockbob  Mariposas   7.0\n",
       "2              SwatSh  Mariposas   7.0\n",
       "3     Timi JeuxATheme  Mariposas   8.0\n",
       "4           prunelles  Mariposas   9.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avis = pd.DataFrame(list(collection.find())).loc[:,[\"author\",\"title\",\"note\"]]\n",
    "df_avis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae35456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 13623 users and 10709 items\n"
     ]
    }
   ],
   "source": [
    "num_users  = df_avis[\"author\"].nunique()\n",
    "num_items  = df_avis[\"title\"].nunique()\n",
    "\n",
    "print(f\"there are {num_users} users and {num_items} items\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edb5e888",
   "metadata": {},
   "source": [
    "## Suppression des jeux qui ont été notés moins de 10 fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3231987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du df avant 246524\n",
      "Taille du df après 169394\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taille du df avant {len(df_avis)}\")\n",
    "# Taille du df avant 246524\n",
    "\n",
    "titles = df_avis['title'].value_counts()\n",
    "titles = titles[titles >= 50].index.to_list()\n",
    "\n",
    "df_avis_k = df_avis[df_avis['title'].isin(titles)]\n",
    "print(f\"Taille du df après {len(df_avis_k)}\")\n",
    "# Taille du df après 5925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "89ea0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#yuyu#</td>\n",
       "      <td>Bubblee Pop</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#yuyu#</td>\n",
       "      <td>KARMAKA</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$hadow</td>\n",
       "      <td>Le Dilemme du Roi</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$lebat@$</td>\n",
       "      <td>Deluxe Camping</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*FitzChevalerie*</td>\n",
       "      <td>7 Wonders - Extension \"Cities\"</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                           title  note\n",
       "0            #yuyu#                     Bubblee Pop   8.5\n",
       "1            #yuyu#                         KARMAKA   8.8\n",
       "2            $hadow               Le Dilemme du Roi   9.0\n",
       "3          $lebat@$                  Deluxe Camping  10.0\n",
       "4  *FitzChevalerie*  7 Wonders - Extension \"Cities\"   8.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on elimine les lignes où un author a note plusieurs fois un jeu\n",
    "# on fait la note moyenne\n",
    "\n",
    "df_avis_k_unique = df_avis_k.groupby(['author','title'])['note'].mean().to_dict()\n",
    "avis_un = []\n",
    "\n",
    "for at,note in df_avis_k_unique.items():\n",
    "  author,title = at\n",
    "  avis_un.append((author,title,note))\n",
    "\n",
    "df_avis_un = pd.DataFrame(avis_un,columns=df_avis_k.columns)\n",
    "df_avis_un.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270ccd2",
   "metadata": {},
   "source": [
    "## Test/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ebf6704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monsieur Guillaume</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morlockbob</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SwatSh</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Timi JeuxATheme</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prunelles</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author      title  note\n",
       "0  Monsieur Guillaume  Mariposas   8.0\n",
       "1          morlockbob  Mariposas   7.0\n",
       "2              SwatSh  Mariposas   7.0\n",
       "3     Timi JeuxATheme  Mariposas   8.0\n",
       "4           prunelles  Mariposas   9.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test = model_selection.train_test_split(df_avis_un, test_size=0.2, random_state=0)\n",
    "df_avis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847740e",
   "metadata": {},
   "source": [
    "## Mean Reciprocal Rank \n",
    "\n",
    "$$ MRR = \\frac{1}{|Q|}\\sum^{|Q|}_{i=1}\\frac{1}{\\text{rank}_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16d09017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr(list_items):\n",
    "    relevant_indexes = np.asarray(list_items).nonzero()[0]\n",
    "    \n",
    "    if len(relevant_indexes) > 0:\n",
    "        \n",
    "        #NOTE:\n",
    "        # relevant_indexes[0] <= Contains the index of the 1st relevant item ([0,0,1] => 2)\n",
    "        \n",
    "        return 1 / (relevant_indexes[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mrr(list_list_items):\n",
    "    rr_list = [rr(list_items) for list_items in list_list_items]\n",
    "    return np.mean(rr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906636b",
   "metadata": {},
   "source": [
    "## Discounted Cumulative Gain\n",
    "\n",
    "$$DCG_p = \\sum^p_{i=1}\\frac{rel_i}{\\log_2{(i+1)}} = rel_1 + \\sum^p_{i=2}\\frac{rel_i}{\\log_2{(i+1)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3285a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        \n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return r[0] +  np.sum(r[1:] / np.log2(np.arange(3, r.size + 2)))\n",
    "        \n",
    "    return 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ed145",
   "metadata": {},
   "source": [
    "$$ nDCG_p = \\frac{DCG_p}{IDCG_p} $$\n",
    "\n",
    "\n",
    "$$ IDCG_p = max(DCG_p) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "13c91a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(r, k):\n",
    "    \"\"\"\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "    \"\"\"\n",
    "    dcg_max =  np.max(dcg_at_k(sorted(r)[::-1], k))\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k)/dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ea7cf",
   "metadata": {},
   "source": [
    "- `already_seen`: Items that were already seen by users. This is for training and not recommending them again\n",
    "- `ground_truth`: Items that will be seen and liked (rating >= 10) by users. This is our ground truth to evaluate our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cdac2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_seen = (\n",
    "    X_train\n",
    "    .groupby(\"author\")[\"title\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    "    )\n",
    "\n",
    "ground_truth = (\n",
    "    X_test[X_test.note >= 10] \n",
    "    .groupby(\"author\")[\"title\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572aefb",
   "metadata": {},
   "source": [
    "### We also need the set of all items that can be recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ac165156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommender system will have to pick a few items from 1324 possible items\n"
     ]
    }
   ],
   "source": [
    "existing_items = set(X_train[\"title\"].unique())\n",
    "print(\"The recommender system will have to pick a few items from\",len(existing_items),\"possible items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047619c",
   "metadata": {},
   "source": [
    "#  Surprise SVD recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b014d7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x13ebb39d0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "\n",
    "data = Dataset.load_from_df(X_train[['author', 'title', 'note']], Reader(rating_scale=(1, 10)))\n",
    "model = SVD()\n",
    "model.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "652f5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_rating_pred(user_item):\n",
    "    user = user_item[\"author\"]\n",
    "    item = user_item[\"title\"]\n",
    "    \n",
    "    prediction = model.predict(user,item)\n",
    "    \n",
    "    return prediction.est\n",
    "\n",
    "X_test[\"svd_prediction\"] = X_test[[\"author\",\"title\"]].apply(svd_rating_pred,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2f61bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.38992377623618 -- MAE: 1.3984831743531199\n"
     ]
    }
   ],
   "source": [
    "mse = ((X_test[\"note\"] - X_test[\"svd_prediction\"])**2).mean()\n",
    "mae = ((X_test[\"note\"] - X_test[\"svd_prediction\"]).abs()).mean()\n",
    "\n",
    "print(f\"MSE: {mse} -- MAE: {mae}\")\n",
    "\n",
    "# MSE: 2.3801853240165443 -- MAE: 1.085783922356087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e89f4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rating_pred(model,user,item):\n",
    "    prediction = model.predict(user,item)\n",
    "    return prediction.est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872d587",
   "metadata": {},
   "source": [
    "###  the relevance list for our MRR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "39e8380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_rel = []\n",
    "    \n",
    "\n",
    "for user,will_see in ground_truth.items():\n",
    "    rel_list = []\n",
    "    will_see = set(will_see)\n",
    "    if user not in already_seen:\n",
    "        continue # si l'utilisateur n'apparait pas dans Xtrain\n",
    "    has_seen = set(already_seen[user])\n",
    "    can_see = [(mid,model_rating_pred(model,user,mid)) for mid in existing_items - has_seen]\n",
    "    \n",
    "    \n",
    "    for movie,score in reversed(sorted(can_see,key=lambda x:x[1])):\n",
    "        if movie in will_see:\n",
    "            rel_list.append(1)\n",
    "            break\n",
    "        else:\n",
    "            rel_list.append(0)        \n",
    "    rel_list[-1] = 1 # when no relevant item exist\n",
    "    list_of_rel.append(rel_list)\n",
    "    \n",
    "\n",
    "svd_mrr = mrr(list_of_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "49d0b925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 36th proposed item is relevant (on 1324)'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"On average, the {int(round(1/svd_mrr,0))}th proposed item is relevant (on {len(existing_items)})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7353c1e2",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 500 jeux nous avons une mrr de 8 sur 5546. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 13 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 27 sur 688."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd352a",
   "metadata": {},
   "source": [
    "# Implicit baseline: popular items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d83042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = X_train.groupby('title')[\"note\"].count().sort_values(ascending=False)\n",
    "popular_item_list = item_counts.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "436b0f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324\n"
     ]
    }
   ],
   "source": [
    "print(len(popular_item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5b4c346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shogun', 'Pandemic Legacy Saison 1', 'Cyclades', 'Dixit', 'Le Roi des Nains', 'Skull', 'Snow Tails', 'Die Baumeister: Mittelalter', 'Non Merci', 'Mille Bornes - Fun & Speed - Voyage']\n"
     ]
    }
   ],
   "source": [
    "print(popular_item_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d99be",
   "metadata": {},
   "source": [
    "### popular recommendation relevance list per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5973913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_rel = []\n",
    "\n",
    "for user,will_see in ground_truth.items():\n",
    "    rel_list = []\n",
    "    will_see = set(will_see)\n",
    "    if user not in already_seen:\n",
    "        continue\n",
    "    has_seen = set(already_seen[user])\n",
    "    \n",
    "    for movie in popular_item_list:\n",
    "        if movie in has_seen:         # User has already seen movie -> Can filter prediction\n",
    "            continue\n",
    "        elif movie in will_see:       # User will see, spot on suggestion !         \n",
    "            rel_list.append(1) # To Complete\n",
    "            break\n",
    "        else:                         # No clue.\n",
    "            rel_list.append(0) # To Complete\n",
    "            \n",
    "    if rel_list[-1] == 1:             # when no relevant item exist, no need to take it into account.\n",
    "        list_of_rel.append(rel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ad05628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 40th proposed item is relevant (on 1324)'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_mrr = mrr(list_of_rel)\n",
    "f\"On average, the {int(round(1/pop_mrr,0))}th proposed item is relevant (on {len(existing_items)})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59a86d7e",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 13 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 49 sur 9786."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926ada1",
   "metadata": {},
   "source": [
    "# Implicit Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8319bf",
   "metadata": {},
   "source": [
    "## Interaction train/test dataset within the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "818b9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.data import Dataset\n",
    "\n",
    "# (a) Create a dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "\n",
    "# (b) Create an internal mapping for users and items (We need to consider train + test)\n",
    "dataset.fit((x for x in df_avis_k[\"author\"]),\n",
    "            (x for x in df_avis_k[\"title\"]))\n",
    "\n",
    "# (c) Create the interaction matrices\n",
    "(train_interactions, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_train.itertuples() if x.note >= 10) # We only consider 5's as interactions\n",
    ") \n",
    "(test_interactions, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_test.itertuples() if x.note >= 10)  # We only consider 5's as interactions\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "76b649a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train interactions: (10876, 1324)\n",
      "test interactions : (10876, 1324)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train interactions: {train_interactions.shape}\")\n",
    "print(f\"test interactions : {test_interactions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "992e2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train interactions: 19703\n",
      "train interactions: 4984\n"
     ]
    }
   ],
   "source": [
    "print(f\"train interactions: {sum(X_train['note']>=10)}\")\n",
    "print(f\"train interactions: {sum(X_test['note']>=10)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7866ab2",
   "metadata": {},
   "source": [
    "## Train the lightFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bf3d687f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x141455af0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "model = LightFM(loss='bpr',random_state=50000)\n",
    "model.fit(train_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a130ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import reciprocal_rank\n",
    "bpr_mrr = reciprocal_rank(model, test_interactions, train_interactions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eafe5f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 59th proposed item is relevant (on 1324)'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"On average, the {int(round(1/bpr_mrr,0))}th proposed item is relevant (on {len(existing_items)})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fbbeec6",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 500 jeux nous avons une mrr de 26 sur 5546. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 14 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 56 sur 9786."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3c946",
   "metadata": {},
   "source": [
    "## We consider EVERY rating as one interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6140de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the interaction matrix\n",
    "(train_interactions_all, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_train.itertuples()) # We only consider 5's as interactions\n",
    ") \n",
    "(test_interactions_all, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_test.itertuples())  # We only consider 5's as interactions\n",
    ") \n",
    "\n",
    "from lightfm import LightFM\n",
    "\n",
    "\n",
    "model_bpr_all = LightFM(loss='bpr',random_state=50000)\n",
    "model_bpr_all.fit(train_interactions_all)\n",
    "\n",
    "bpr_mrr_all = reciprocal_rank(model_bpr_all, test_interactions_all, train_interactions_all).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "10b0362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 47th proposed item is relevant (on 1324)'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"On average, the {int(round(1/bpr_mrr_all,0))}th proposed item is relevant (on {len(existing_items)})\"\n",
    "\n",
    "# 'On average, the 34th proposed item is relevant (on 9819)'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "989a9aa2",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 3 sur 5546. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 6 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 34 sur 9786."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896bb46",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

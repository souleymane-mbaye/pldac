{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de7f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo  import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import decomposition, naive_bayes, preprocessing, model_selection, metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import model_selection\n",
    "#! pip install scikit-surprise\n",
    "from surprise import NormalPredictor, BaselineOnly, SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34814b",
   "metadata": {},
   "source": [
    "# Chargement des données AVIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397272d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host=\"localhost\", port=27017)\n",
    "db = client[\"PLDAC_01\"] \n",
    "collection = db[\"avis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ea1183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monsieur Guillaume</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morlockbob</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SwatSh</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Timi JeuxATheme</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prunelles</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author      title  note\n",
       "0  Monsieur Guillaume  Mariposas   8.0\n",
       "1          morlockbob  Mariposas   7.0\n",
       "2              SwatSh  Mariposas   7.0\n",
       "3     Timi JeuxATheme  Mariposas   8.0\n",
       "4           prunelles  Mariposas   9.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avis = pd.DataFrame(list(collection.find())).loc[:,[\"author\",\"title\",\"note\"]]\n",
    "df_avis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae35456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 13623 users and 10709 items\n"
     ]
    }
   ],
   "source": [
    "num_users  = df_avis[\"author\"].nunique()\n",
    "num_items  = df_avis[\"title\"].nunique()\n",
    "\n",
    "print(f\"there are {num_users} users and {num_items} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5e888",
   "metadata": {},
   "source": [
    "## Suppression des autheurs qui ont noté moins de 10 jeux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3231987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du df avant 246524\n",
      "Taille du df après 216410\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taille du df avant {len(df_avis)}\")\n",
    "# Taille du df avant 246524\n",
    "\n",
    "authors = df_avis['author'].value_counts()\n",
    "authors = authors[authors >= 10].index.to_list()\n",
    "\n",
    "df_avis_k = df_avis[df_avis['author'].isin(authors)]\n",
    "print(f\"Taille du df après {len(df_avis_k)}\")\n",
    "# Taille du df après 5925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ea0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*FitzChevalerie*</td>\n",
       "      <td>7 Wonders - Extension \"Cities\"</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*FitzChevalerie*</td>\n",
       "      <td>7 Wonders - Extension \"Wonder Pack\"</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*FitzChevalerie*</td>\n",
       "      <td>A Few Acres of Snow</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*FitzChevalerie*</td>\n",
       "      <td>Archipelago</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*FitzChevalerie*</td>\n",
       "      <td>Archipelago : Solo Expansion</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                title  note\n",
       "0  *FitzChevalerie*       7 Wonders - Extension \"Cities\"   8.0\n",
       "1  *FitzChevalerie*  7 Wonders - Extension \"Wonder Pack\"   7.4\n",
       "2  *FitzChevalerie*                  A Few Acres of Snow  10.0\n",
       "3  *FitzChevalerie*                          Archipelago  10.0\n",
       "4  *FitzChevalerie*         Archipelago : Solo Expansion  10.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on elimine les lignes où un author a note plusieurs fois un jeu\n",
    "# on fait la note moyenne\n",
    "\n",
    "df_avis_k_unique = df_avis_k.groupby(['author','title'])['note'].mean().to_dict()\n",
    "avis_un = []\n",
    "\n",
    "for at,note in df_avis_k_unique.items():\n",
    "  author,title = at\n",
    "  avis_un.append((author,title,note))\n",
    "\n",
    "df_avis_un = pd.DataFrame(avis_un,columns=df_avis_k.columns)\n",
    "df_avis_un.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb98c89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_avis_un' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x7/bmqxr1zd3lxd_kcxxw9physr0000gn/T/ipykernel_8246/850807747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nombre de notes restants:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_avis_un\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_avis_un' is not defined"
     ]
    }
   ],
   "source": [
    "print('Nombre de notes restants:', len(df_avis_un))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270ccd2",
   "metadata": {},
   "source": [
    "## Test/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ebf6704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monsieur Guillaume</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morlockbob</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SwatSh</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Timi JeuxATheme</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prunelles</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author      title  note\n",
       "0  Monsieur Guillaume  Mariposas   8.0\n",
       "1          morlockbob  Mariposas   7.0\n",
       "2              SwatSh  Mariposas   7.0\n",
       "3     Timi JeuxATheme  Mariposas   8.0\n",
       "4           prunelles  Mariposas   9.0"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test = model_selection.train_test_split(df_avis_un, test_size=0.2, random_state=0)\n",
    "df_avis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847740e",
   "metadata": {},
   "source": [
    "## Mean Reciprocal Rank \n",
    "\n",
    "$$ MRR = \\frac{1}{|Q|}\\sum^{|Q|}_{i=1}\\frac{1}{\\text{rank}_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "16d09017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr(list_items):\n",
    "    relevant_indexes = np.asarray(list_items).nonzero()[0]\n",
    "    \n",
    "    if len(relevant_indexes) > 0:\n",
    "        \n",
    "        #NOTE:\n",
    "        # relevant_indexes[0] <= Contains the index of the 1st relevant item ([0,0,1] => 2)\n",
    "        \n",
    "        return 1 / (relevant_indexes[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mrr(list_list_items):\n",
    "    rr_list = [rr(list_items) for list_items in list_list_items]\n",
    "    return np.mean(rr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906636b",
   "metadata": {},
   "source": [
    "## Discounted Cumulative Gain\n",
    "\n",
    "$$DCG_p = \\sum^p_{i=1}\\frac{rel_i}{\\log_2{(i+1)}} = rel_1 + \\sum^p_{i=2}\\frac{rel_i}{\\log_2{(i+1)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3285a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        \n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return r[0] +  np.sum(r[1:] / np.log2(np.arange(3, r.size + 2)))\n",
    "        \n",
    "    return 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ed145",
   "metadata": {},
   "source": [
    "$$ nDCG_p = \\frac{DCG_p}{IDCG_p} $$\n",
    "\n",
    "\n",
    "$$ IDCG_p = max(DCG_p) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "13c91a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(r, k):\n",
    "    \"\"\"\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "    \"\"\"\n",
    "    dcg_max =  np.max(dcg_at_k(sorted(r)[::-1], k))\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k)/dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ea7cf",
   "metadata": {},
   "source": [
    "- `already_seen`: Items that were already seen by users. This is for training and not recommending them again\n",
    "- `ground_truth`: Items that will be seen and liked (rating >= 10) by users. This is our ground truth to evaluate our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cdac2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_seen = (\n",
    "    X_train\n",
    "    .groupby(\"author\")[\"title\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    "    )\n",
    "\n",
    "ground_truth = (\n",
    "    X_test[X_test.note >= 10] \n",
    "    .groupby(\"author\")[\"title\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572aefb",
   "metadata": {},
   "source": [
    "### We also need the set of all items that can be recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ac165156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommender system will have to pick a few items from 5546 possible items\n"
     ]
    }
   ],
   "source": [
    "existing_items = set(X_train[\"title\"].unique())\n",
    "print(\"The recommender system will have to pick a few items from\",len(existing_items),\"possible items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047619c",
   "metadata": {},
   "source": [
    "#  Surprise SVD recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b014d7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x149b4a100>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "\n",
    "data = Dataset.load_from_df(X_train[['author', 'title', 'note']], Reader(rating_scale=(1, 10)))\n",
    "model = SVD()\n",
    "model.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "652f5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_rating_pred(user_item):\n",
    "    user = user_item[\"author\"]\n",
    "    item = user_item[\"title\"]\n",
    "    \n",
    "    prediction = model.predict(user,item)\n",
    "    \n",
    "    return prediction.est\n",
    "\n",
    "X_test[\"svd_prediction\"] = X_test[[\"author\",\"title\"]].apply(svd_rating_pred,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2f61bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.2693530368019967 -- MAE: 1.3822816528993016\n"
     ]
    }
   ],
   "source": [
    "mse = ((X_test[\"note\"] - X_test[\"svd_prediction\"])**2).mean()\n",
    "mae = ((X_test[\"note\"] - X_test[\"svd_prediction\"]).abs()).mean()\n",
    "\n",
    "print(f\"MSE: {mse} -- MAE: {mae}\")\n",
    "\n",
    "# MSE: 2.3801853240165443 -- MAE: 1.085783922356087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e89f4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rating_pred(model,user,item):\n",
    "    prediction = model.predict(user,item)\n",
    "    return prediction.est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872d587",
   "metadata": {},
   "source": [
    "###  the relevance list for our MRR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "39e8380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_rel = []\n",
    "    \n",
    "\n",
    "for user,will_see in ground_truth.items():\n",
    "    rel_list = []\n",
    "    will_see = set(will_see)\n",
    "    has_seen = set(already_seen[user])\n",
    "    can_see = [(mid,model_rating_pred(model,user,mid)) for mid in existing_items - has_seen]\n",
    "    \n",
    "    \n",
    "    for movie,score in reversed(sorted(can_see,key=lambda x:x[1])):\n",
    "        if movie in will_see:\n",
    "            rel_list.append(1)\n",
    "            break\n",
    "        else:\n",
    "            rel_list.append(0)        \n",
    "    rel_list[-1] = 1 # when no relevant item exist\n",
    "    list_of_rel.append(rel_list)\n",
    "    \n",
    "\n",
    "svd_mrr = mrr(list_of_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "49d0b925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 8th proposed item is relevant (on 5546)'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"On average, the {int(round(1/svd_mrr,0))}th proposed item is relevant (on {len(existing_items)})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7353c1e2",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 500 jeux nous avons une mrr de 8 sur 5546. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 13 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 45 sur 9786."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd352a",
   "metadata": {},
   "source": [
    "# Implicit baseline: popular items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2d83042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = X_train.groupby('title')[\"note\"].count().sort_values(ascending=False)\n",
    "popular_item_list = item_counts.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "436b0f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5546\n"
     ]
    }
   ],
   "source": [
    "print(len(popular_item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5b4c346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Saint Pétersbourg', 'Colt Express', 'Race for the Galaxy', 'Troyes', 'Schotten-Totten', 'Pandémie', \"L'Âge de Pierre\", 'Pingouins', 'Augustus', 'Myrmes']\n"
     ]
    }
   ],
   "source": [
    "print(popular_item_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d99be",
   "metadata": {},
   "source": [
    "### popular recommendation relevance list per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5973913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_rel = []\n",
    "\n",
    "for user,will_see in ground_truth.items():\n",
    "    rel_list = []\n",
    "    will_see = set(will_see)\n",
    "    has_seen = set(already_seen[user])\n",
    "    \n",
    "    for movie in popular_item_list:\n",
    "        if movie in has_seen:         # User has already seen movie -> Can filter prediction\n",
    "            continue\n",
    "        elif movie in will_see:       # User will see, spot on suggestion !         \n",
    "            rel_list.append(1) # To Complete\n",
    "            break\n",
    "        else:                         # No clue.\n",
    "            rel_list.append(0) # To Complete\n",
    "            \n",
    "    if rel_list[-1] == 1:             # when no relevant item exist, no need to take it into account.\n",
    "        list_of_rel.append(rel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ad05628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 5th proposed item is relevant (on 5546)'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_mrr = mrr(list_of_rel)\n",
    "f\"On average, the {int(round(1/pop_mrr,0))}th proposed item is relevant (on {len(existing_items)})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59a86d7e",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 500 jeux nous avons une mrr de 5 sur 5546. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 13 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 49 sur 9786."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926ada1",
   "metadata": {},
   "source": [
    "# Implicit Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8319bf",
   "metadata": {},
   "source": [
    "## Interaction train/test dataset within the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "818b9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.data import Dataset\n",
    "\n",
    "# (a) Create a dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "\n",
    "# (b) Create an internal mapping for users and items (We need to consider train + test)\n",
    "dataset.fit((x for x in df_avis_k[\"author\"]),\n",
    "            (x for x in df_avis_k[\"title\"]))\n",
    "\n",
    "# (c) Create the interaction matrices\n",
    "(train_interactions, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_train.itertuples() if x.note >= 10) # We only consider 5's as interactions\n",
    ") \n",
    "(test_interactions, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_test.itertuples() if x.note >= 10)  # We only consider 5's as interactions\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "76b649a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train interactions: (36, 6122)\n",
      "test interactions : (36, 6122)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train interactions: {train_interactions.shape}\")\n",
    "print(f\"test interactions : {test_interactions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "992e2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train interactions: 2115\n",
      "train interactions: 510\n"
     ]
    }
   ],
   "source": [
    "print(f\"train interactions: {sum(X_train['note']>=10)}\")\n",
    "print(f\"train interactions: {sum(X_test['note']>=10)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7866ab2",
   "metadata": {},
   "source": [
    "## Train the lightFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "bf3d687f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x139628190>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "model = LightFM(loss='bpr',random_state=50000)\n",
    "model.fit(train_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9a130ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import reciprocal_rank\n",
    "bpr_mrr = reciprocal_rank(model, test_interactions, train_interactions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "eafe5f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 26th proposed item is relevant (on 5546)'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"On average, the {int(round(1/bpr_mrr,0))}th proposed item is relevant (on {len(existing_items)})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fbbeec6",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 500 jeux nous avons une mrr de 26 sur 5546. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 14 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 56 sur 9786."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3c946",
   "metadata": {},
   "source": [
    "## We consider EVERY rating as one interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6140de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the interaction matrix\n",
    "(train_interactions_all, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_train.itertuples()) # We only consider 5's as interactions\n",
    ") \n",
    "(test_interactions_all, weights) = dataset.build_interactions(\n",
    "    ((x.author, x.title) for x in X_test.itertuples())  # We only consider 5's as interactions\n",
    ") \n",
    "\n",
    "from lightfm import LightFM\n",
    "\n",
    "\n",
    "model_bpr_all = LightFM(loss='bpr',random_state=50000)\n",
    "model_bpr_all.fit(train_interactions_all)\n",
    "\n",
    "bpr_mrr_all = reciprocal_rank(model_bpr_all, test_interactions_all, train_interactions_all).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "10b0362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, the 3th proposed item is relevant (on 5546)'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"On average, the {int(round(1/bpr_mrr_all,0))}th proposed item is relevant (on {len(existing_items)})\"\n",
    "\n",
    "# 'On average, the 34th proposed item is relevant (on 9819)'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "989a9aa2",
   "metadata": {},
   "source": [
    "En éliminant les utilisateurs ayant noter moins de 500 jeux nous avons une mrr de 3 sur 5546. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 100 jeux nous avons une mrr de 6 sur 8497. </br>\n",
    "\n",
    "En éliminant les utilisateurs ayant noter moins de 10 jeux nous avons une mrr de 34 sur 9786."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896bb46",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
